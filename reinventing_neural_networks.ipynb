{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and boilerplate to make graphs look better\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import wave\n",
    "from IPython.display import Audio\n",
    "\n",
    "def setup_graph(title='', x_label='', y_label='', fig_size=None):\n",
    "    fig = plt.figure()\n",
    "    if fig_size != None:\n",
    "        fig.set_size_inches(fig_size[0], fig_size[1])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinventing neural networks\n",
    "\n",
    "(Intentionally reinventing the wheel)\n",
    "\n",
    "I wanted to try to derive the ideas of machine learning for myself. I do have some knowledge (so it's not completely independent of course), but I want to try to derive a lot of the ideas myself.\n",
    "\n",
    "The first sample problem is to write a machine learning algorithm to learn the xor function.\n",
    "\n",
    "So here's the xor logic table:\n",
    "\n",
    "| x0 | x1 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 0 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 1  | 1  | 0 |\n",
    "\n",
    "So we have a 2 input function that returns 1 value - something like this:\n",
    "\n",
    "<img src=\"images/xor_network1.png\"  style=\"width: 50%; height: 50%\" />\n",
    "\n",
    "My initial thought is that we can convolute through some linear model, and adjust coefficients to get the right answer.\n",
    "\n",
    "So the equation would look something like this:\n",
    "\n",
    "$W0*x0 + W1*x1 = y$\n",
    "\n",
    "You could put this into matrix form and add a bias coefficient, in which case it would look like this:\n",
    "\n",
    "$Ax +b = y$ where A is the vector containing the 2 weights, x is a free variable to hold the features - x0 and x1, and y is the vector of labels) - so something like this:\n",
    "\n",
    "<img src=\"images/xor_matrix_form1.png\" style=\"width: 50%; height: 50%\" />\n",
    "\n",
    "Before trying to write an algorithm to optimize the values of W0 and W1, let's first make sure this model is powerful enough to work for the xor function. After thinking for a minute, I was able to determine that the values W0 = 1 and W2 = -1 would be good values, since if we plug those weights into the equation, $W0*x0 + W1*x1 = y$, we get $1*x0 + -1*x1$, and that should come out to the values of y (or at least, the value should be > 0.5 for (0, 1) and (1, 0), and < 0.5 for (0, 0) and (1, 1) ). And it turns out, that works:\n",
    "* for x0=0 and x1=1: `1*0 + -1*0 = 0`\n",
    "* for x0=0 and x1=1: `1*0 + -1*1 = -1`\n",
    "* for x0=0 and x1=1: `1*1 + -1*0 = 1`\n",
    "* for x0=0 and x1=1: `1*0 + -1*0 = 0`\n",
    "\n",
    "Shoot - when I first ran the numbers in my head, I was thinking the 2nd equation came out to 1, not -1. And actually, graphing it out, xor would look like this:\n",
    "\n",
    "<img src=\"images/xor_graph.png\"  style=\"width: 400px; height: 400px;\" />\n",
    "\n",
    "And as you can clearly see, that is not linearly separable. That is why, when I tried a linear classifier, it didn't work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0]), array([0]), array([0]), array([0])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that I'm making 10x repetitions of the logic table.\n",
    "X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]*10\n",
    "y = [0, 1, 1, 0]*10\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X, y)\n",
    "\n",
    "[clf.predict([sample]) for sample in [(0, 0), (0, 1), (1, 0), (1, 1)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is wrong - presumably because a linear model simply isn't powerful enough, whereas something like RandomForest is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0]), array([1]), array([1]), array([0])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "[clf.predict([sample]) for sample in [(0, 0), (0, 1), (1, 0), (1, 1)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So RandomForest clearly works, but linear models do not. So we need to add some power to our model. How can we change it to be more powerful? Some ideas that come to mind:\n",
    "\n",
    "* Move from a linear to a polynomial model.\n",
    "* Add another layer to the network.\n",
    "\n",
    "Would these work? Is it possible that adding layers is similar in function to adding polynomials?\n",
    "\n",
    "Let's go with adding a layer...\n",
    "\n",
    "So the very simplest layer I could think of would be this:\n",
    "\n",
    "<img src=\"images/xor_network2.png\"  style=\"width: 50%; height: 50%;\" />\n",
    "(note: weights should be w0, w1, w2, and w3)\n",
    "\n",
    "But I know that typically, when I've seen pictures of neural networks, the inputs from one layer go to each of the nodes in the next layer - more like this:\n",
    "\n",
    "<img src=\"images/xor_network3.png\"  style=\"width: 50%; height: 50%;\" />\n",
    "(note: weights should be w0, w1, w2, and w3)\n",
    "\n",
    "I think the reason for this is that, in the prior network (without the cross in the middle), the 2 layers of weights are still only being added to the same input, which is really functionally the same as just having 1 layer. So I'm going to test out the network with the cross.\n",
    "\n",
    "So now we have 4 weights to play with. Let's see if I could imagine a solution where the weights are adjusted so that xor works... on second thought, that sounds like a good job for a program - let's do it that way.\n",
    "\n",
    "### Finding weights programmatically\n",
    "\n",
    "A few initial thoughts on writing a program to learn:\n",
    "* The inputs for the second layer are not the inputs, but the outputs of the previous layer.\n",
    "* We probably can't just keep 4 variables (one for each weight we are trying to tune), because we might optimize for the first sample, and then reoptimize for the second, and third, and so forth. One solution would be to generate a number of hypotheses for the weights, and keep them all in memory, and then find the one that minimizes error for all samples. Later, we can try to actually tweak the weights.\n",
    "\n",
    "So let's try to write this. First, some helper functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def rand_weight(weight_min, weight_max):\n",
    "    \"\"\"Generates a uniformly random weight between weight_min and weight_max.\"\"\"\n",
    "    return random.random() * (weight_max - weight_min) + weight_min\n",
    "\n",
    "def gen_hypothesis(weight_min, weight_max, num_weights):\n",
    "    return tuple([rand_weight(weight_min, weight_max) for i in range(num_weights)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.706551715382767"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_weight(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.814122290019785,\n",
       " 1.4739675581934826,\n",
       " -4.116735204818674,\n",
       " -3.690855764792645)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_hypothesis(-5, 5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node functionality\n",
    "\n",
    "Next, let's define the functionality of each node. I know there's the concept of an [Activation function](https://en.wikipedia.org/wiki/Activation_function) in common neural network terminology. I suppose there are several ways a given node could function:\n",
    "* It could always output some discrete value (like 1 and 0, or -1 and 1).\n",
    "* It could output a continuous value bounded within some range like a probability (e.g. 0 to 1).\n",
    "* It could output an unbounded continuous value.\n",
    "\n",
    "For starters, I'm going to just go with what seems the simplest - it's just going to output an unbounded continuous value taking by multiplying the input by the weight. So the equation to determine the output of a given node will be: $node(x) = w0 * x$.\n",
    "\n",
    "On second thought, though... now that we have a hidden layer, those nodes will have more than one input. So how should that be handled? It could be handled a few ways:\n",
    "* We could make each input have its own weight.\n",
    "* We could use the same weight for all of the inputs.\n",
    "\n",
    "I'm again going to choose the dumbest easiest approach and say each node only has a single weight (even though, if I recall correctly, neural networks typically have different weights for each input - but we'll get there eventually). And if there is more than 1 sample, we'll just add them all together.\n",
    "\n",
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, weight):\n",
    "        self.weight = weight\n",
    "    def run(self, node_input):\n",
    "        if type(node_input) != list:\n",
    "            node_input = [node_input]\n",
    "        return sum([self.weight * input_val for input_val in node_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the node implementation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 50, 60]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Node(10)\n",
    "[n.run([1]), n.run([5]), n.run([1, 2, 3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good. Now let's try to write the network.\n",
    "\n",
    "Actually, just trying to write this, I immediately realize that we need to do some sort of convolution at the output node (to join its 2 inputs), so let's just add a 5th weight for that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_1(weights, sample):\n",
    "    input_layer = [Node(weights[0]), Node(weights[1])]\n",
    "    hidden_layer = [Node(weights[3]), Node(weights[2])]\n",
    "    output_layer = Node(weights[4])\n",
    "    \n",
    "    input_layer_output = [input_layer[i].run(sample[i]) for i in range(len(input_layer))]\n",
    "    hidden_layer_output = [hidden_layer[i].run(input_layer_output) for i in range(len(hidden_layer))]\n",
    "    output_layer_output = output_layer.run(hidden_layer_output)\n",
    "    \n",
    "    return output_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_1([0, 0, 0, 0, 0], [1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_1([1, 1, 1, 1, 1], [1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should double the above\n",
    "neural_net_1([1, 1, 1, 1, 2], [1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_1([2, 2, 2, 2, 2], [10, 10, 10, 10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work as expected. Let's now write an algorithm to generate a bunch of weight hypotheses, and choose the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetPredictor:\n",
    "    def __init__(self, num_hypotheses=1000, weight_min=-5, weight_max=5):\n",
    "        # generate hypotheses randomly\n",
    "        self.hypotheses = [gen_hypothesis(weight_min, weight_max, 5) for i in range(num_hypotheses)]\n",
    "        self.hypothesis_to_error = {h: 0 for h in self.hypotheses}\n",
    "        self.trained_weights = [0]*5\n",
    "    \n",
    "    def add_sample(self, sample, expected_value):\n",
    "        for h in self.hypotheses:\n",
    "            network_value = neural_net_1(h, sample)\n",
    "            # print('sample = {}, network_value = {}'.format(sample, network_value))\n",
    "            err = (network_value - expected_value)**2\n",
    "            self.hypothesis_to_error[h] += err\n",
    "    \n",
    "    def train(self, samples, labels):\n",
    "        for index in range(len(samples)):\n",
    "            self.add_sample(samples[index], labels[index])\n",
    "        \n",
    "        # Find hypothesis with lowest error\n",
    "        best_hypothesis = self.hypotheses[0]\n",
    "        lowest_err = 10000000\n",
    "        for hyp_index in range(len(self.hypotheses)):\n",
    "            hyp = self.hypotheses[hyp_index]\n",
    "            err = self.hypothesis_to_error[hyp]\n",
    "            if err < lowest_err:\n",
    "                lowest_err = err\n",
    "                best_hypothesis = hyp\n",
    "        \n",
    "        self.trained_weights = best_hypothesis\n",
    "        print('Best hypothesis weights: {}'.format(best_hypothesis))\n",
    " \n",
    "    def predict(self, sample):\n",
    "        return neural_net_1(self.trained_weights, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-4.835723019141343, -2.151626509195678, -2.5743759790844845, 2.6450847102501864, -1.304615234513605)\n",
      "Predictions: [0.0, 0.19848257068022424, 0.4460842678014316, 0.644566838481655]\n"
     ]
    }
   ],
   "source": [
    "# Note that I'm making 10x repetitions of the logic table.\n",
    "X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]*10\n",
    "y = [0, 1, 1, 0]*10\n",
    "\n",
    "xor_predictor = NeuralNetPredictor()\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (1.2691361815047593, 1.323306590493453, 4.080570405796291, -4.129541464772575, -4.301876441138667)\n",
      "Predictions: [0.0, 0.278777618248764, 0.2673656765975103, 0.5461432948462743]\n"
     ]
    }
   ],
   "source": [
    "xor_predictor = NeuralNetPredictor()\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (1.4182072209952157, 2.994979664378551, -1.7268446644494349, 3.033152215017221, 0.08999821095586835)\n",
      "Predictions: [0.0, 0.3521058100508829, 0.1667320176853846, 0.5188378277362674]\n"
     ]
    }
   ],
   "source": [
    "xor_predictor = NeuralNetPredictor()\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It doesn't work!\n",
    "\n",
    "Okay, so this is clearly not working. At this point, we're not using converting into classes based on the output value, but still, I'd expect the output values to be higher at (0, 1) and (1, 0). But instead, it seems like they pretty much correspond to the input values (1, 1) is almost always the highest, (0, 0) is always 0, and (0, 1) and (1, 0) are almost always about half of (1, 1). Interestingly, the 4 classes summed together is very near 1 - which is kind of surprising considering I'm not explicitly doing any probability normalizations.\n",
    "\n",
    "So why is this not working? My guess is that, since the \"expected value\" used to calculate the error with is always either 0 or 1, it's being almost entirely factored out by large network output values. So to fix this, we'd probably want the network values to be something in the 0 to 1 range (to match the classes).\n",
    "\n",
    "Well, we'll try that another day.\n",
    "\n",
    "## Normalize neuronal output (fix attempt #1)\n",
    "\n",
    "In the previous attempt, the output power of a neuron was proportional to the magnitude of it's input. But from doing a bit of research on [Neural action potentials](https://en.wikipedia.org/wiki/Action_potential), it seems like the output of a neuron should not be proportinal to the input:\n",
    "\n",
    "> \"The amplitude of an action potential is independent of the amount of current that produced it. In other words, larger currents do not create larger action potentials. Therefore, action potentials are said to be all-or-none signals, since either they occur fully or they do not occur at all.\" (https://en.wikipedia.org/wiki/Action_potential#%22All-or-none%22_principle)\n",
    "\n",
    "So, let's try that...\n",
    "\n",
    "The first question is, what is it outputing? The first thought I have is \"0 or 1\". Seems simple enough. But how can I determine if it should be 0 or 1? My first thought is the [sigmod function](https://en.wikipedia.org/wiki/Sigmoid_function), which converts from real numbers to a number between 0 and 1, f(x) = 0.5. This would basically then just convert from [-infinity, 0] -> 0 and [0, +infinity] -> 1, assuming 0.5 is considered the threshold for \"high\". That's not very useful unless we can either:\n",
    "* Shift the sigmoid function to the left or right\n",
    "* Change the threshold used to count as \"1\"/high.\n",
    "\n",
    "Both of these are possible, and these could both be used as parameters which can be learned. A few more thoughts:\n",
    "* If the output of a neuron is normalized to 1, the more input neurons there are, the more the sigmoid function would be shifted to the right. In other words, the shift to the right should be linearly proportional to the number of input neurons.\n",
    "* Another option... would be to move from the output of the neuron being \"0 or 1\" to \"-1 or 1\"... That would allow the sigmoid function to be centered on 0 without biasing against firing... maybe that's a good idea. That way, we could only learn the threshold, rather than having to worry about optimizing both the shift/bias and the thresold.\n",
    "\n",
    "Doing a quick search, it appears the sigmoid function is a good activation function - almost all activation functions on wikipedia have that shape: https://en.wikipedia.org/wiki/Activation_function. So that's a good sign.\n",
    "\n",
    "I'm now leaning toward the -1, 1 outputs for the neuron after looking at the activation potential of neurons, which appears to vary between negative and positive voltages:\n",
    "\n",
    "<img src=\"images/neuron_activation_potential.png\" style=\"width: 40%; height: 40%\" />\n",
    "\n",
    "## Sigmoid function\n",
    "\n",
    "Let's try playing with the sigmoid function a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10, 10, 1000)\n",
    "y = [sigmoid(i) for i in x]\n",
    "setup_graph(title='sigmoid', x_label='x', y_label='sigmoid(x) = 1/(1+e^-x)', fig_size=(12,6))\n",
    "plt.grid(True)\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at this, it appears that shifting left and right would be functionally equivalent to lowering/raising the \"activation threhsold\". Another thing that could be useful, potentially, is to spread out the graph horizontally... but let's not worry about that for now.\n",
    "\n",
    "So, we now have an activation function for each \"neuron\". So what knobs do we now have which can be learned?\n",
    "* Activation threshold - some value betweeen 0 and 1. This will be applied to the output of the sigmoid function, which itself has as inputs the summation of the values of all the input neurons, each of which will either be -1 or 1.\n",
    "* The weights applied to each input neuron.\n",
    "\n",
    "But let's see... do we really need the weights? Can we just tweak the activation threshold / bias? If we did this, then we would still use linear convolution - it would just be a linear convolution where every coefficient is 1 and there is no bias.\n",
    "* Side question: how does nature tweak activation threshold? Or maybe it has some other way of \"learning\"?\n",
    "\n",
    "Let's try to implement this idea - **each neuron has an activation threshold / bias, and those are the values that are learned.**\n",
    "\n",
    "First, let's see if we can tweak the activation threshold/bias of the sigmoid. We should be able to move it up/down by doing f(x) -> f(x - bias)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_sigmoid(bias):\n",
    "    x = np.linspace(-10, 10, 1000)\n",
    "    y = [sigmoid(i - bias) for i in x]\n",
    "\n",
    "    setup_graph(title='sigmoid', x_label='x', y_label='sigmoid(x) = 1/(1+e^-x)', fig_size=(12,6))\n",
    "    plt.grid(True)\n",
    "    plt.plot(x, y)\n",
    "    plt.show()\n",
    "\n",
    "show_sigmoid(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_sigmoid(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something that just occurred to me is that, if the output of our neuron is all or nothing, the sigmoid/bias is kind of the same as an if statement like `if input > bias: 1; else: -1`. So actually, to simplify even further, let's try to just use an if statement and tweak the \"activation_threshold\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, activation_threshold):\n",
    "        self.activation_threshold = activation_threshold\n",
    "        \n",
    "    def run(self, node_input):\n",
    "        if type(node_input) != list:\n",
    "            node_input = [node_input]\n",
    "        input_sum = sum(node_input)\n",
    "        if input_sum >= self.activation_threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neuron(0).run([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neuron(0).run([-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neuron(5).run([2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neuron(5).run([2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool - hard to get any simpler than this. Let's go back and try to implement that same neural network to predict xor...\n",
    "\n",
    "## Attempt 2\n",
    "\n",
    "Here's the network again:\n",
    "\n",
    "<img src=\"images/xor_network3.png\"  style=\"width: 50%; height: 50%;\" />\n",
    "(note: weights should be w0, w1, w2, and w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_2(thresholds, sample):\n",
    "    input_layer = [Neuron(thresholds[0]), Neuron(thresholds[1])]\n",
    "    hidden_layer = [Neuron(thresholds[3]), Neuron(thresholds[2])]\n",
    "    output_layer = Neuron(thresholds[4])\n",
    "    \n",
    "    input_layer_output = [input_layer[i].run(sample[i]) for i in range(len(input_layer))]\n",
    "    hidden_layer_output = [hidden_layer[i].run(input_layer_output) for i in range(len(hidden_layer))]\n",
    "    output_layer_output = output_layer.run(hidden_layer_output)\n",
    "    \n",
    "    return output_layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except these are not really weights, but activation thresholds now. So let's see, if the last activation `theresholds[4]` is really high, the output should always be -1. Let's use this as a rough smoke test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_2([0, 0, 0, 0, 100], [1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if it's really low, the output should typically be high:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_net_2([0, 0, 0, 0, -100], [1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good enough for me. Let's try to write a trainer for this.\n",
    "\n",
    "Again (for anyone reading this), I understand this is a HORRIBLE training algorithm - this is really just a test of the neurons, rather than the training algorithm itself. Randomly generating solutions is about as unsophisticated of a training algorithm possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetTrainer2:\n",
    "    def __init__(self, neural_net_func, num_hypotheses=1000, threshold_min=-5, threshold_max=5):\n",
    "        # generate hypotheses randomly\n",
    "        self.neural_net_func = neural_net_func\n",
    "        self.hypotheses = [gen_hypothesis(threshold_min, threshold_max, 5) for i in range(num_hypotheses)]\n",
    "        self.hypothesis_to_error = {h: 0 for h in self.hypotheses}\n",
    "        \n",
    "        # Trained weights (start at 0) - almost certainly bad until train()'ed\n",
    "        self.trained_thresholds = [0]*5\n",
    "    \n",
    "    def add_sample(self, sample, expected_value):\n",
    "        for h in self.hypotheses:\n",
    "            network_value = self.neural_net_func(h, sample)\n",
    "            # print('sample = {}, network_value = {}'.format(sample, network_value))\n",
    "            err = (network_value - expected_value)**2\n",
    "            self.hypothesis_to_error[h] += err\n",
    "    \n",
    "    def train(self, samples, labels):\n",
    "        for index in range(len(samples)):\n",
    "            self.add_sample(samples[index], labels[index])\n",
    "        \n",
    "        # Find hypothesis with lowest error\n",
    "        best_hypothesis = self.hypotheses[0]\n",
    "        lowest_err = 10000000\n",
    "        for hyp_index in range(len(self.hypotheses)):\n",
    "            hyp = self.hypotheses[hyp_index]\n",
    "            err = self.hypothesis_to_error[hyp]\n",
    "            if err < lowest_err:\n",
    "                lowest_err = err\n",
    "                best_hypothesis = hyp\n",
    "        \n",
    "        self.trained_thresholds = best_hypothesis\n",
    "        print('Best hypothesis weights: {}'.format(best_hypothesis))\n",
    " \n",
    "    def predict(self, sample):\n",
    "        return self.neural_net_func(self.trained_thresholds, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (2.628474400738364, 1.6115061304711347, -3.376169418044711, 0.6379000877486787, -2.477611910124832)\n",
      "Predictions: [1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Note that I'm making 10x repetitions of the logic table.\n",
    "X = [[0, 0],\n",
    "     [0, 1],\n",
    "     [1, 0],\n",
    "     [1, 1]]*10\n",
    "y = [0, 1, 1, 0]*10\n",
    "\n",
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-3.2496744299729166, 3.7513463957571833, -3.3266980137764266, -3.732550991505741, -1.33243859281965)\n",
      "Predictions: [1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-3.5403862816578924, -1.1822749503866978, 4.640251643184293, 0.1592391231822976, -3.072080465005642)\n",
      "Predictions: [1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (3.1295257393348646, -0.37632723552326475, -4.796511229256844, -2.40702164572675, 0.01356449634245216)\n",
      "Predictions: [1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fail.** This is worse than before, since it seems to simply optimize for all 1 outputs, and the weights seem random. Why is this?\n",
    "\n",
    "What if the error function is not very good because we are squaring the error, but the outputs are only either -1 and 1, so squaring 1 yields 1.... What if we make the outputs larger, like -2 and 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, activation_threshold):\n",
    "        self.activation_threshold = activation_threshold\n",
    "        \n",
    "    def run(self, node_input):\n",
    "        if type(node_input) != list:\n",
    "            node_input = [node_input]\n",
    "        input_sum = sum(node_input)\n",
    "        if input_sum >= self.activation_threshold:\n",
    "            return 2\n",
    "        else:\n",
    "            return -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-4.511982182951603, -2.899993434942789, 0.7201391932610992, -2.085998381590317, 3.6520963844805543)\n",
      "Predictions: [2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (1.986396944139858, -3.6853876056797654, -1.3335861094167711, -1.9123963309692336, -3.7480456787143765)\n",
      "Predictions: [2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, that doesn't work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-6.808625433333447, 9.289828019609999, 5.139754493308875, -1.0013509162198169, -0.005776643552195537)\n",
      "Predictions: [2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2, threshold_min=-10, threshold_max=10)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(0, 0), (0, 1), (1, 0), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohhhh.... I know. It's because the labels are 0, but the output is -1 and 1, which are equidistant from 0. So maybe it will work if I use -1 in place of 0 in the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, activation_threshold):\n",
    "        self.activation_threshold = activation_threshold\n",
    "        \n",
    "    def run(self, node_input):\n",
    "        if type(node_input) != list:\n",
    "            node_input = [node_input]\n",
    "        input_sum = sum(node_input)\n",
    "        if input_sum >= self.activation_threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (0.45280500411716584, 0.08621623715362503, -3.4129747425502677, -0.8432143671732248, 1.1255942985130822)\n",
      "Predictions: [-1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Note that I'm making 10x repetitions of the logic table.\n",
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]*10\n",
    "y = [-1, 1, 1, -1]*10\n",
    "\n",
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2, num_hypotheses=10000)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that isn't correct, but at least it seems to be converting to a prediction of `[-1, 1, 1, 1]`. But why? Is it possible there aren't enough neurons to learn xor? What if I try to learn \"or\" or \"and\"?\n",
    "\n",
    "### Attempt at learning \"or\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-0.2722838143109021, -0.7997278386441176, -2.5337467766377255, -1.2030666543714617, 1.3147527484451)\n",
      "Predictions: [-1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Note that I'm making 10x repetitions of the logic table.\n",
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]*10\n",
    "y = [-1, 1, 1, 1]*10\n",
    "\n",
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2, num_hypotheses=10000)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, that worked! What about \"and\"?\n",
    "\n",
    "### Attempt at learning \"and\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (0.32724388633882473, -0.17305249315130844, 1.6592034742259933, -3.533461005859518, 0.9445998582037527)\n",
      "Predictions: [-1, -1, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Note that I'm making 10x repetitions of the logic table.\n",
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]*10\n",
    "y = [-1, -1, -1, 1]*10\n",
    "\n",
    "xor_predictor = NeuralNetTrainer2(neural_net_func=neural_net_2, num_hypotheses=10000)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweet, that works too! So I think I don't have enough neurons to learn \"xor\". Let's see if I build a larger neural network. Let's try just adding one more neuron in the hidden layer...\n",
    "\n",
    "## Attempt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_3(thresholds, sample):\n",
    "    input_layer = [Neuron(thresholds[0]), Neuron(thresholds[1])]\n",
    "    hidden_layer = [Neuron(thresholds[2]), Neuron(thresholds[3]), Neuron(thresholds[4])]\n",
    "    output_layer = Neuron(thresholds[5])\n",
    "    \n",
    "    input_layer_output = [input_layer[i].run(sample[i]) for i in range(len(input_layer))]\n",
    "    hidden_layer_output = [hidden_layer[i].run(input_layer_output) for i in range(len(hidden_layer))]\n",
    "    output_layer_output = output_layer.run(hidden_layer_output)\n",
    "    \n",
    "    return output_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obviously, I'll want abstract this code at some point\n",
    "\n",
    "class StocasticNeuralNetTrainer:\n",
    "    def __init__(self, neural_net_func, num_knobs, num_hypotheses=1000, threshold_min=-5, threshold_max=5):\n",
    "        self.neural_net_func = neural_net_func\n",
    "        \n",
    "        # generate hypotheses randomly\n",
    "        self.hypotheses = [gen_hypothesis(threshold_min, threshold_max, num_knobs) for i in range(num_hypotheses)]\n",
    "        self.hypothesis_to_error = {h: 0 for h in self.hypotheses}\n",
    "        \n",
    "        # Trained weights (start at 0) - almost certainly bad until train()'ed\n",
    "        self.trained_thresholds = [0]*num_knobs\n",
    "    \n",
    "    def add_sample(self, sample, expected_value):\n",
    "        for h in self.hypotheses:\n",
    "            network_value = self.neural_net_func(h, sample)\n",
    "            # print('sample = {}, network_value = {}'.format(sample, network_value))\n",
    "            err = (network_value - expected_value)**2\n",
    "            self.hypothesis_to_error[h] += err\n",
    "    \n",
    "    def train(self, samples, labels):\n",
    "        for index in range(len(samples)):\n",
    "            self.add_sample(samples[index], labels[index])\n",
    "        \n",
    "        # Find hypothesis with lowest error\n",
    "        best_hypothesis = self.hypotheses[0]\n",
    "        lowest_err = 10000000\n",
    "        for hyp_index in range(len(self.hypotheses)):\n",
    "            hyp = self.hypotheses[hyp_index]\n",
    "            err = self.hypothesis_to_error[hyp]\n",
    "            if err < lowest_err:\n",
    "                lowest_err = err\n",
    "                best_hypothesis = hyp\n",
    "        \n",
    "        self.trained_thresholds = best_hypothesis\n",
    "        print('Best hypothesis weights: {}'.format(best_hypothesis))\n",
    " \n",
    "    def predict(self, sample):\n",
    "        return self.neural_net_func(self.trained_thresholds, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-0.9375573492773412, 0.022234681214007068, -0.838957933413754, -4.1290886314422295, -1.9360330302674509, -0.4437439094198954)\n",
      "Predictions: [-1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Note that I'm making 10x repetitions of the logic table.\n",
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]*10\n",
    "y = [-1, 1, 1, -1]*10\n",
    "\n",
    "xor_predictor = StocasticNeuralNetTrainer(neural_net_func=neural_net_3, num_knobs=6, num_hypotheses=10000)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, let's try two more neurons in the hidden layer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_4(thresholds, sample):\n",
    "    input_layer = [Neuron(thresholds[0]), Neuron(thresholds[1])]\n",
    "    hidden_layer = [Neuron(thresholds[2]), Neuron(thresholds[3]),\n",
    "                    Neuron(thresholds[4]), Neuron(thresholds[5]), Neuron(thresholds[6])]\n",
    "    output_layer = Neuron(thresholds[7])\n",
    "    \n",
    "    input_layer_output = [input_layer[i].run(sample[i]) for i in range(len(input_layer))]\n",
    "    hidden_layer_output = [hidden_layer[i].run(input_layer_output) for i in range(len(hidden_layer))]\n",
    "    output_layer_output = output_layer.run(hidden_layer_output)\n",
    "    \n",
    "    return output_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-0.11109716802769576, 0.516490214968556, -0.8042769067565558, 0.3641258617735712, 2.6256869204799003, 4.09896880704998, -0.7847015406797215, -2.8096838306238547)\n",
      "Predictions: [-1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Note that I'm making 10x repetitions of the logic table.\n",
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]*20\n",
    "y = [-1, 1, 1, -1]*20\n",
    "\n",
    "xor_predictor = StocasticNeuralNetTrainer(neural_net_func=neural_net_4, num_knobs=8, num_hypotheses=10000)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no good - it appears that this neural network is still unable to learn anything but linearly seperable distinctions. Somehow, adding more neurons in this single hidden layer is NOT adding any robustness. My guess is that adding all these neurons together is functionally equivalent to one weighted neuron.  What if I add another hidden layer?\n",
    "\n",
    "## Attempt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_5(thresholds, sample):\n",
    "    input_layer = [Neuron(thresholds[0]), Neuron(thresholds[1])]\n",
    "    hidden_layer = [Neuron(thresholds[2]), Neuron(thresholds[3]), Neuron(thresholds[4])]\n",
    "    hidden_layer2 = [Neuron(thresholds[5]), Neuron(thresholds[6]), Neuron(thresholds[7])]\n",
    "    output_layer = Neuron(thresholds[8])\n",
    "    \n",
    "    input_layer_output = [input_layer[i].run(sample[i]) for i in range(len(input_layer))]\n",
    "    hidden_layer_output = [hidden_layer[i].run(input_layer_output) for i in range(len(hidden_layer))]\n",
    "    hidden_layer_output2 = [hidden_layer2[i].run(hidden_layer_output) for i in range(len(hidden_layer2))]\n",
    "    output_layer_output = output_layer.run(hidden_layer_output2)\n",
    "    \n",
    "    return output_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-0.17513285385608057, 0.7013863554966111, -1.883921911037747, -1.1442650414639957, 1.2597020311777927, -2.380533761310245, 2.4687002726034146, 1.0737061167811195, -2.046070414233988)\n",
      "Predictions: [-1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Note that I'm making 10x repetitions of the logic table.\n",
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]*10\n",
    "y = [-1, 1, 1, -1]*10\n",
    "\n",
    "xor_predictor = StocasticNeuralNetTrainer(neural_net_func=neural_net_5, num_knobs=9, num_hypotheses=10000)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not working. Here's a few possible ideas to fix it:\n",
    "* Add weights for each neuron input\n",
    "* Add multiple output neurons - one for each class.\n",
    "\n",
    "Let's try adding weights to each neuron input...\n",
    "\n",
    "## Attempt 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, activation_threshold, input_weights):\n",
    "        self.activation_threshold = activation_threshold\n",
    "        self.input_weights = input_weights\n",
    "        \n",
    "    def run(self, node_input):\n",
    "        if type(node_input) != list:\n",
    "            node_input = [node_input]\n",
    "        input_sum = sum([node_input[i]*self.input_weights[i] for i in range(len(self.input_weights))])\n",
    "        if input_sum >= self.activation_threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neuron(100, [50]).run(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neuron(101, [50]).run(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neuron(101, [50, 20, 30]).run([1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neuron(100, [50, 20, 30]).run([1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_6(knobs, sample):\n",
    "    # For the input layer, weight inputs to 1, and keep activation at 0\n",
    "    # Note that this input_layer is functionally nil - it just passes through the sample values, so it\n",
    "    # could be eliminated. But to keep with the previous examples, let's keep it. Also, it works to just pass\n",
    "    # the values through since our input values need no conversion. It's possible that some input\n",
    "    # value would benefit from some sort of conversion (like multiplying by 10 or something).\n",
    "    input_layer = [Neuron(0, [1]), Neuron(0, [1])]\n",
    "    hidden_layer = [Neuron(knobs[0], [knobs[1], knobs[2]]),\n",
    "                    Neuron(knobs[3], [knobs[4], knobs[5]]),\n",
    "                    Neuron(knobs[6], [knobs[7], knobs[8]])]\n",
    "    output_layer = Neuron(knobs[9], [knobs[10], knobs[11], knobs[12]])\n",
    "    \n",
    "    input_layer_output = [input_layer[i].run(sample[i]) for i in range(len(input_layer))]\n",
    "    hidden_layer_output = [hidden_layer[i].run(input_layer_output) for i in range(len(hidden_layer))]\n",
    "    output_layer_output = output_layer.run(hidden_layer_output)\n",
    "    \n",
    "    return output_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-3.3312315420723273, -0.6186899538079658, -2.6508818921540267, 2.493483508092309, -0.4926664023882301, -2.581662465372375, 4.409037962549409, 2.7846911252382416, 4.351451406463973, 3.9076180372499234, 0.7566588797370342, -3.4622432181823495, -0.40637788765934246)\n",
      "Predictions: [-1, 1, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]\n",
    "y = [-1, 1, 1, -1]\n",
    "\n",
    "xor_predictor = StocasticNeuralNetTrainer(neural_net_func=neural_net_6, num_knobs=13, num_hypotheses=10000)\n",
    "xor_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([xor_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUCCESS\n",
    "\n",
    "**Wow, that works!** Even with a single training set!\n",
    "\n",
    "So it appears that weighting neuron inputs is extremely important.  Let's verify that it also works for \"and\" and \"or\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-4.529244947610081, 2.936969444290293, -1.2990161660039643, -1.1425525715508247, -1.1171099453546085, 2.637223421259989, -1.450576551862369, 2.099111039420592, -1.4684208032486898, -0.5733192672310663, -1.2018061387049062, 0.6553881171323823, 0.16330598417973619)\n",
      "Predictions: [-1, -1, -1, 1]\n"
     ]
    }
   ],
   "source": [
    "# AND\n",
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]\n",
    "y = [-1, -1, -1, 1]\n",
    "\n",
    "and_predictor = StocasticNeuralNetTrainer(neural_net_func=neural_net_6, num_knobs=13, num_hypotheses=10000)\n",
    "and_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([and_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-3.1605694002727445, 3.3801485891287033, -1.6049544308097783, -3.5303776982494615, -3.075839726860643, -1.5574362967649593, -2.6872142597094806, 3.5848938828733186, 2.1433849729883754, -1.703647433794182, -0.2625786694309795, 0.4854661813110184, 3.0861353218611924)\n",
      "Predictions: [-1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# OR\n",
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]\n",
    "y = [-1, 1, 1, 1]\n",
    "\n",
    "or_predictor = StocasticNeuralNetTrainer(neural_net_func=neural_net_6, num_knobs=13, num_hypotheses=10000)\n",
    "or_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([or_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hypothesis weights: (-0.533528739179701, -0.7368093945337026, -1.8028438243444977, 4.250712610532435, 1.7505676222829827, 4.7405926648756065, 1.5256770444732783, -4.860280343429942, -4.473899186181715, -2.413998309817739, 0.720939834638723, -1.4772823865981177, 2.483843316813747)\n",
      "Predictions: [1, 1, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "# NAND\n",
    "X = [[-1, -1],\n",
    "     [-1, 1],\n",
    "     [1, -1],\n",
    "     [1, 1]]\n",
    "y = [1, 1, 1, -1]\n",
    "\n",
    "nand_predictor = StocasticNeuralNetTrainer(neural_net_func=neural_net_6, num_knobs=13, num_hypotheses=10000)\n",
    "nand_predictor.train(X, y)\n",
    "print('Predictions: {}'.format([nand_predictor.predict(x) for x in [(-1, -1), (-1, 1), (1, -1), (1, 1)]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "So this works very well. Why are weighted neuron inputs so important? I think that without weights, each input neuron is equally important, which cuts flexibility.\n",
    "\n",
    "Next steps\n",
    "* How can we actually train the network (without just generating random hypotheses)?\n",
    "    - Up to this point, we're just generating random configurations of knobs and picking the best configuration. The next step is to write an algorithm to adjust the knobs.\n",
    "* How could we do multi-class classifiers? (probably with multiple output neurons)\n",
    "* How does this behave with probabilistic relationships between inputs and outputs? (in these boolean logic functions, there is 100% correlation between inputs and outputs)\n",
    "\n",
    "Questions\n",
    "* Does nature have the concept of weighted neuron inputs? If so, how is it implemented in nature?\n",
    "* Brains run on bayesian probability - how can I incorporate bayesian probability into my neural network model?\n",
    "* What is the role of neurotransmitters in reinforcing inputs?\n",
    "* Can we make the connections between various neurons self-wire (rather than hardcoding them)? Can the labels be just another input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
